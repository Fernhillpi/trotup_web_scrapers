{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path\n",
    "PATH = \"/Users/Immy/Desktop/chromedriver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists for results:\n",
    "prices= []\n",
    "adnames = []\n",
    "ad_details = []\n",
    "\n",
    "#text of subcategories\n",
    "category = []\n",
    "#numeric placeholders for subcategories\n",
    "subcat = []\n",
    "\n",
    "#set url to horsequest advanced search page\n",
    "driver = webdriver.Chrome(PATH)\n",
    "url = 'https://www.horsequest.co.uk/search'\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "#define functions\n",
    "\n",
    "#determine number of pages for the search results, save as an int\n",
    "def page_counter(x):\n",
    "    if x == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        lastpagetxt = x.text\n",
    "        lastpage= int(lastpagetxt.split()[-1])\n",
    "        return lastpage\n",
    "\n",
    "#retrieve data on price, title, and details on a single page\n",
    "def get_data():\n",
    "    cards = driver.find_elements_by_class_name('card-main')\n",
    "    \n",
    "    for card in cards:\n",
    "        #retrieve advert title\n",
    "        titles = card.find_elements_by_class_name('card-title')\n",
    "        for i in titles:\n",
    "            titletext = i.text\n",
    "            adnames.append(titletext)\n",
    "    \n",
    "    for card in cards:\n",
    "        #retrieve advert price\n",
    "        pricelab = card.find_elements_by_class_name('card-price')\n",
    "        for i in pricelab:\n",
    "            result = i.text\n",
    "            prices.append(result)\n",
    "\n",
    "    #retrieve advert details *if present*\n",
    "    for card in cards:\n",
    "        details=card.find_elements_by_class_name(\"card-breedInfo\")\n",
    "        if len(details) == 1:\n",
    "            for i in details:\n",
    "                detailtext = i.text\n",
    "                ad_details.append(detailtext)\n",
    "        #if details are absent, append \"blank\"\n",
    "        else:\n",
    "            ad_details.append(\"BLANK\")\n",
    "\n",
    "    #add a numeric placeholder for the subcategory being scraped \n",
    "    for card in cards:\n",
    "        subcat.append(subcatno)\n",
    "\n",
    "#go to each page, and then extract data          \n",
    "def main():\n",
    "    #select category 'horses for sale'\n",
    "    dd1 = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//*[(@id = 'ContentPanel_ddlCategory')]/option[text()='Horses For Sale']\")\n",
    "        ))\n",
    "    dd1.click()\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    #identify the subcategories in the second dropdown, then save them to \"options\"\n",
    "    dd2 = Select(driver.find_element_by_xpath(\"//*[(@id = 'ContentPanel_ddlSubCategory')]\"))\n",
    "    options = dd2.options\n",
    "    #save the text names of horse types to a list for later use\n",
    "    for option in options:\n",
    "        category.append(option.text)\n",
    "\n",
    "    #iterate through subcats in this dropdown- click each subcat, then click search:\n",
    "    for item in range(1,len(options)):\n",
    "\n",
    "        #pick a subcat\n",
    "        dd2 = Select(driver.find_element_by_xpath(\"//*[(@id = 'ContentPanel_ddlSubCategory')]\"))\n",
    "        time.sleep(1)\n",
    "        dd2.select_by_index(item)\n",
    "        time.sleep(1)\n",
    "\n",
    "        #scroll to search button\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "\n",
    "        #click go\n",
    "        element = driver.find_element_by_name('ctl00$ContentPanel$btnsubmit')\n",
    "        actions = ActionChains(driver)\n",
    "        actions.move_to_element(element).click().perform()\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        #look if there are multiple pages to scrape. if so, calc num of pages. \n",
    "        try:\n",
    "            pagerange= driver.find_element_by_css_selector(\".pagination-pagenumber\")\n",
    "            allpages= page_counter(pagerange)\n",
    "        except NoSuchElementException:\n",
    "            pagerange = 1   \n",
    "        subcatno = item\n",
    "        #extract data\n",
    "        for j in range(allpages):\n",
    "            try:\n",
    "            #if a next page button is present: get data from this page, then click next page \n",
    "                nextpage = driver.find_element_by_xpath(\"//*[(@id = 'ContentPanel_ucTopPagination_hlPageNext')]\")\n",
    "                get_data()\n",
    "                nextpage.click()\n",
    "                time.sleep(1)\n",
    "            #otherwise, get data from this page\n",
    "            except NoSuchElementException:\n",
    "                get_data()\n",
    "\n",
    "                #go back to starter page\n",
    "                driver.get(url)\n",
    "                #click first dropdown and re-input horses for sale- this prevents dropdown timeout\n",
    "                dd1 = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//*[(@id = 'ContentPanel_ddlCategory')]/option[text()='Horses For Sale']\")\n",
    "                ))\n",
    "\n",
    "                dd1.click()\n",
    "\n",
    "                time.sleep(1)\n",
    "                #open second drop down, save its categories to options- to prevent dropdown timeout\n",
    "                dd2 = Select(driver.find_element_by_xpath(\"//*[(@id = 'ContentPanel_ddlSubCategory')]\"))\n",
    "                options = dd2.options\n",
    "                \n",
    "main()\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to interrupt a scrape midway through\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** CREATE A DATAFRAME FOR THE DATA***\n",
    "\n",
    "\n",
    "note- if scrape is interrupted, lists will likely be different lengths and if so, df will not be possible to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make empty df\n",
    "df= pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#advert title column\n",
    "df[\"Name\"] = adnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#details column\n",
    "df[\"Details\"]= ad_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price column\n",
    "df[\"Price\"]= prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric subcategory column\n",
    "df[\"Category\"] = subcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return a text equivalent of the numeric subcat\n",
    "def gettitle(x):\n",
    "    return category[x - 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make text subcategory column eg allrounders\n",
    "df['Type'] = list(map(gettitle,df[\"Category\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#head of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
